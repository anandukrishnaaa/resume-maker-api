"""
AI-Powered Resume Generator API with Multi-User Support
"""

import os
import json
import hashlib
import uuid
import yaml
import logging
from datetime import datetime
from typing import Optional, Dict, Any, List
from pathlib import Path

from fastapi import FastAPI, Depends, HTTPException, status, Header
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field
from sqlmodel import (
    SQLModel,
    Field as SQLField,
    create_engine,
    Session,
    select,
    JSON,
    Column,
)

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

from rendercv.data.models import RenderCVDataModel
import rendercv.renderer as renderer

from environs import Env
from huey import SqliteHuey

# ============================================================================
# Logging Setup
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)

# ============================================================================
# Environment & Config
# ============================================================================
env = Env()
env.read_env()
api_key = env.str("OPENROUTER_API_KEY", "your-key-here")
API_TOKEN = "secret-token-123"

app = FastAPI(title="Resume Generator AI")

# ============================================================================
# Huey Configuration (Task Queue)
# ============================================================================
huey = SqliteHuey(filename="tmp/huey_queue.db")


# ============================================================================
# Pydantic Output Models (For Structured AI Response)
# ============================================================================
class EducationEntry(BaseModel):
    """Education entry matching RenderCV format"""

    institution: str
    area: str
    degree: str
    start_date: str  # YYYY-MM format
    end_date: str  # YYYY-MM or "present"
    highlights: List[str] = Field(default_factory=list)
    location: Optional[str] = None


class ExperienceEntry(BaseModel):
    """Experience entry matching RenderCV format"""

    company: str
    position: str
    start_date: str  # YYYY-MM format
    end_date: str  # YYYY-MM or "present"
    location: Optional[str] = None
    highlights: List[str] = Field(default_factory=list)


class ProjectEntry(BaseModel):
    """Project entry matching RenderCV format"""

    name: str
    date: str
    highlights: List[str] = Field(default_factory=list)


class SkillEntry(BaseModel):
    """Skill entry matching RenderCV OneLineEntry format"""

    label: str
    details: str


class ResumeSections(BaseModel):
    """The main sections of the resume generated by AI"""

    summary: List[str] = Field(
        description="A brief professional summary as a list of 2-4 strings"
    )
    education: List[EducationEntry]
    experience: List[ExperienceEntry]
    projects: Optional[List[ProjectEntry]] = None
    skills: List[SkillEntry]


# ============================================================================
# Database Models with Multi-User Support
# ============================================================================
class UserProfile(SQLModel, table=True):
    """Stores user-specific profile information"""

    id: Optional[int] = SQLField(default=None, primary_key=True)
    user_id: str = SQLField(index=True, unique=True)  # External user identifier
    profile_data: str  # JSON string of work history, skills, etc.
    created_at: datetime = SQLField(default_factory=datetime.now)
    updated_at: datetime = SQLField(default_factory=datetime.now)


class PersonalInfo(SQLModel, table=True):
    """Stores personal contact information per user"""

    id: Optional[int] = SQLField(default=None, primary_key=True)
    user_id: str = SQLField(foreign_key="userprofile.user_id", index=True, unique=True)
    name: str
    email: str
    phone: str
    country_code: str = SQLField(default="+91")
    location: str
    social_networks: str  # JSON string
    updated_at: datetime = SQLField(default_factory=datetime.now)


class JobDescription(SQLModel, table=True):
    id: Optional[int] = SQLField(default=None, primary_key=True)
    user_id: str = SQLField(foreign_key="userprofile.user_id", index=True)  # NEW
    title: str
    company: str
    description: str
    content_hash: str = SQLField(
        index=True
    )  # Removed unique=True to allow per-user duplicates
    created_at: datetime = SQLField(default_factory=datetime.now)


class JobAnalysis(SQLModel, table=True):
    id: Optional[int] = SQLField(default=None, primary_key=True)
    user_id: str = SQLField(foreign_key="userprofile.user_id", index=True)  # NEW
    job_id: int = SQLField(foreign_key="jobdescription.id")
    analysis_text: str
    created_at: datetime = SQLField(default_factory=datetime.now)


class ResumeContent(SQLModel, table=True):
    """Stores the AI-generated resume JSON"""

    id: Optional[int] = SQLField(default=None, primary_key=True)
    user_id: str = SQLField(foreign_key="userprofile.user_id", index=True)  # NEW
    task_id: str = SQLField(foreign_key="tasklog.task_id", index=True)
    job_id: int = SQLField(foreign_key="jobdescription.id")
    content: str  # JSON string of ResumeSections
    created_at: datetime = SQLField(default_factory=datetime.now)


class TaskLog(SQLModel, table=True):
    """Tracks the lifecycle of a request via UUID"""

    task_id: str = SQLField(primary_key=True, index=True)
    user_id: str = SQLField(foreign_key="userprofile.user_id", index=True)  # NEW
    job_id: Optional[int] = SQLField(default=None, foreign_key="jobdescription.id")
    status: str = SQLField(default="pending")
    total_tokens: int = SQLField(default=0)
    logs: List[str] = SQLField(default=[], sa_column=Column(JSON))
    output_folder: Optional[str] = None  # NEW: Stores "output/{task_id}/"
    pdf_path: Optional[str] = None
    created_at: datetime = SQLField(default_factory=datetime.now)
    updated_at: datetime = SQLField(default_factory=datetime.now)


# ============================================================================
# Database & Security
# ============================================================================
DATABASE_URL = "sqlite:///./resume_generator.db"
engine = create_engine(
    DATABASE_URL, echo=False, connect_args={"check_same_thread": False}
)


def create_db_and_tables():
    SQLModel.metadata.create_all(engine)


def get_session():
    with Session(engine) as session:
        yield session


async def verify_api_key(x_api_key: str = Header(...)):
    if x_api_key != API_TOKEN:
        raise HTTPException(status_code=401, detail="Invalid API Key")


async def get_user_id(x_user_id: str = Header(...)) -> str:
    """Extract user_id from request header"""
    if not x_user_id:
        raise HTTPException(status_code=400, detail="X-User-Id header required")
    return x_user_id


# ============================================================================
# API Input Models
# ============================================================================
class JobRequest(BaseModel):
    title: str
    company: str
    description: str


class PersonalInfoUpdate(BaseModel):
    name: str
    email: str
    phone: str
    country_code: str
    location: str
    social_networks: Optional[List[Dict[str, str]]] = None


class ProfileDataUpdate(BaseModel):
    """Update user's work history, education, skills"""

    education: Optional[List[Dict[str, Any]]] = None
    experience: Optional[List[Dict[str, Any]]] = None
    skills: Optional[Dict[str, List[str]]] = None


class TaskResponse(BaseModel):
    task_id: str
    status: str
    message: str


class AnalysisContentResponse(BaseModel):
    task_id: str
    job_id: int
    analysis_text: str


class ResumeContentResponse(BaseModel):
    task_id: str
    job_id: int
    content: Dict[str, Any]
    created_at: datetime


class StatusResponse(BaseModel):
    task_id: str
    status: str
    logs: List[str]
    total_tokens: int
    pdf_url: Optional[str] = None
    output_folder: Optional[str] = None  # NEW


class StatsResponse(BaseModel):
    total_tasks: int
    total_tokens_used: int
    recent_tasks: List[Dict[str, Any]]


class UserProfileResponse(BaseModel):
    user_id: str
    profile_data: Dict[str, Any]
    personal_info: Dict[str, Any]
    created_at: datetime
    updated_at: datetime


# ============================================================================
# AI Agents & Helpers
# ============================================================================
def get_openrouter_model():
    return OpenAIChat(
        id="google/gemini-2.5-flash-lite",
        api_key=api_key,
        base_url="https://openrouter.ai/api/v1",
    )


def create_jd_analyzer_agent() -> Agent:
    db = SqliteDb(db_file="tmp/agents.db", session_table="jd_analyzer_sessions")
    return Agent(
        name="JD Analyzer",
        model=get_openrouter_model(),
        instructions=[
            "You are an expert job description analyzer.",
            "Analyze the provided job description and extract key insights.",
            "Format your response as structured text with clear sections.",
            "Focus on: 1. Required Skills, 2. Soft Skills, 3. Experience, 4. Keywords, 5. Responsibilities.",
        ],
        db=db,
        markdown=True,
    )


def create_resume_generator_agent() -> Agent:
    db = SqliteDb(db_file="tmp/agents.db", session_table="resume_generator_sessions")
    return Agent(
        name="Resume Generator",
        model=get_openrouter_model(),
        instructions=[
            "You are an expert resume writer.",
            "You will be given a Job Description, an AI Analysis of that job, and a User Profile.",
            "Your task is to select and adapt the user's experience to fit the job.",
            "Do NOT invent false information. Use the user's actual profile but rephrase highlights to match keywords.",
            "For dates, use YYYY-MM format or 'present'.",
            "",
            "IMPORTANT FORMATTING RULES:",
            "- For skills: label is the category (e.g., 'Programming Languages'), details is a comma-separated string (e.g., 'Python, JavaScript, Go')",
            "- For projects: Only include if the user has relevant projects. If no projects, return empty list or null.",
            "- For experience highlights: Use action verbs and quantify achievements when possible",
            "- Keep summary to 2-4 concise bullet points",
        ],
        output_schema=ResumeSections,
        db=db,
        markdown=False,
    )


def get_or_create_user_profile(session: Session, user_id: str):
    """Get or create profile for specific user"""
    user = session.exec(
        select(UserProfile).where(UserProfile.user_id == user_id)
    ).first()

    personal = session.exec(
        select(PersonalInfo).where(PersonalInfo.user_id == user_id)
    ).first()

    if not user:
        default_profile = {
            "education": [
                {
                    "institution": "University of Tech",
                    "area": "Computer Science",
                    "degree": "BS",
                    "start_date": "2020-01",
                    "end_date": "2024-01",
                }
            ],
            "experience": [
                {
                    "company": "Tech Corp",
                    "position": "Software Developer",
                    "start_date": "2024-02",
                    "end_date": "present",
                    "highlights": [
                        "Developed scalable APIs using Python and FastAPI",
                        "Optimized database queries reducing response time by 40%",
                    ],
                }
            ],
            "skills": {
                "languages": ["Python", "JavaScript"],
                "tools": ["Git", "Docker", "AWS"],
            },
        }
        user = UserProfile(user_id=user_id, profile_data=json.dumps(default_profile))
        session.add(user)
        session.commit()
        session.refresh(user)

    if not personal:
        personal = PersonalInfo(
            user_id=user_id,
            name="John Doe",
            email="john@example.com",
            phone="9876543210",
            country_code="+91",
            location="Thiruvananthapuram, Kerala, India",
            social_networks=json.dumps(
                [{"network": "LinkedIn", "username": "johndoe"}]
            ),
        )
        session.add(personal)
        session.commit()
        session.refresh(personal)

    return user, personal


# ============================================================================
# HUEY TASKS (Background Workers)
# ============================================================================
@huey.task()
def process_analysis_task(
    task_id: str,
    user_id: str,
    title: str,
    company: str,
    description: str,
    job_id: int,
    auto_resume: bool = False,
):
    """Background task: Runs AI analysis. Can optionally trigger resume generation."""
    logger.info(
        f"--- Starting Analysis Task: {task_id} (User: {user_id}, Auto-Resume: {auto_resume}) ---"
    )

    with Session(engine) as session:
        task = session.get(TaskLog, task_id)
        if not task:
            return

        try:
            task.status = "analysis_in_progress"
            task.logs.append(f"[{datetime.now()}] Analysis started (Worker)")
            session.add(task)
            session.commit()

            analyzer = create_jd_analyzer_agent()
            prompt = f"Analyze:\nTitle: {title}\nCompany: {company}\n\n{description}"
            response = analyzer.run(prompt)

            analysis = JobAnalysis(
                user_id=user_id, job_id=job_id, analysis_text=response.content
            )
            session.add(analysis)

            # Safe Token Logging
            tokens = 0
            if response.metrics:
                try:
                    tokens = response.metrics.to_dict().get("total_tokens", 0)
                except:
                    tokens = getattr(response.metrics, "total_tokens", 0)

            task.total_tokens += int(tokens)
            task.logs.append(f"[{datetime.now()}] Analysis complete. Tokens: {tokens}")
            task.status = "analysis_complete"
            session.add(task)
            session.commit()

            if auto_resume:
                process_resume_task(task_id)

        except Exception as e:
            logger.error(f"Analysis Error: {e}", exc_info=True)
            task.status = "error"
            task.logs.append(f"[{datetime.now()}] Error: {str(e)}")
            session.add(task)
            session.commit()


@huey.task()
def process_resume_task(task_id: str):
    """Background task: Generates JSON -> YAML -> PDF in dedicated folder per task"""
    logger.info(f"--- Starting Resume Task: {task_id} ---")

    with Session(engine) as session:
        task = session.get(TaskLog, task_id)
        if not task or not task.job_id:
            return

        try:
            task.status = "resume_in_progress"
            task.logs.append(f"[{datetime.now()}] Resume generation started (Worker)")
            session.add(task)
            session.commit()

            # Fetch Data
            jd = session.get(JobDescription, task.job_id)
            analysis = session.exec(
                select(JobAnalysis)
                .where(JobAnalysis.job_id == task.job_id)
                .where(JobAnalysis.user_id == task.user_id)
                .order_by(JobAnalysis.id.desc())
            ).first()
            user, personal = get_or_create_user_profile(session, task.user_id)

            if not analysis:
                raise ValueError("No analysis found")

            # 1. AI Generation
            generator = create_resume_generator_agent()
            prompt = f"Generate Resume Content for:\nJOB: {jd.title}\nANALYSIS: {analysis.analysis_text}\nUSER: {user.profile_data}"
            response = generator.run(prompt)
            resume_sections_obj = response.content

            # Metrics
            tokens = 0
            if response.metrics:
                try:
                    tokens = response.metrics.to_dict().get("total_tokens", 0)
                except:
                    tokens = getattr(response.metrics, "total_tokens", 0)

            task.total_tokens += int(tokens)
            task.logs.append(
                f"[{datetime.now()}] Structured content generated. Tokens: {tokens}"
            )

            # 2. Convert to dict and store in DB
            sections_dict = resume_sections_obj.model_dump(exclude_none=True)

            # Store AI-generated resume content
            resume_content = ResumeContent(
                user_id=task.user_id,
                task_id=task_id,
                job_id=task.job_id,
                content=json.dumps(sections_dict),
            )
            session.add(resume_content)
            session.commit()

            # 3. Fix sections format for RenderCV
            if "projects" in sections_dict and not sections_dict["projects"]:
                del sections_dict["projects"]

            if "skills" in sections_dict:
                skills_formatted = []
                for skill in sections_dict["skills"]:
                    if "label" in skill and "details" in skill:
                        skills_formatted.append(skill)
                sections_dict["skills"] = skills_formatted

            # 4. Format phone with country code
            full_phone = personal.country_code + personal.phone.replace(
                "-", ""
            ).replace(" ", "")

            # Assemble Full Resume Data
            full_cv_dict = {
                "cv": {
                    "name": personal.name,
                    "location": personal.location,
                    "email": personal.email,
                    "phone": full_phone,
                    "sections": sections_dict,
                },
                "design": {"theme": "classic"},
            }

            # Add social_networks only if not empty
            social_networks = json.loads(personal.social_networks)
            if social_networks:
                full_cv_dict["cv"]["social_networks"] = social_networks

            # 5. Render PDF in dedicated task folder
            output_dir = Path("output") / task_id  # NEW: One folder per task
            output_dir.mkdir(parents=True, exist_ok=True)

            # Store folder path in task
            task.output_folder = str(output_dir)

            # Create the RenderCV data model from the dictionary
            cv_data_model = RenderCVDataModel(**full_cv_dict)

            task.logs.append(
                f"[{datetime.now()}] Data model created, generating Typst file..."
            )
            session.add(task)
            session.commit()

            # Generate Typst file and copy theme files
            typst_file_path = renderer.create_a_typst_file_and_copy_theme_files(
                cv_data_model, output_dir
            )

            task.logs.append(
                f"[{datetime.now()}] Typst file generated at {typst_file_path}"
            )
            session.add(task)
            session.commit()

            # Render PDF from the Typst file
            pdf_path = renderer.render_a_pdf_from_typst(typst_file_path)

            task.pdf_path = str(pdf_path)
            task.status = "resume_complete"
            task.logs.append(
                f"[{datetime.now()}] PDF rendered successfully at {pdf_path}"
            )

            session.add(task)
            session.commit()

            logger.info(f"--- Finished Resume Task: {task_id} ---")

        except Exception as e:
            logger.error(f"Resume Error: {e}", exc_info=True)
            task.status = "error"
            task.logs.append(f"[{datetime.now()}] Error: {str(e)}")
            session.add(task)
            session.commit()


# ============================================================================
# API Endpoints - User Profile Management
# ============================================================================
@app.on_event("startup")
def on_startup():
    create_db_and_tables()


@app.post("/users/create", dependencies=[Depends(verify_api_key)])
def create_user(
    user_id: str = Depends(get_user_id), session: Session = Depends(get_session)
):
    """Create a new user profile"""
    existing = session.exec(
        select(UserProfile).where(UserProfile.user_id == user_id)
    ).first()

    if existing:
        raise HTTPException(status_code=400, detail="User already exists")

    user, personal = get_or_create_user_profile(session, user_id)

    return {
        "status": "created",
        "user_id": user_id,
        "message": "User profile created with default data",
    }


@app.get(
    "/users/profile",
    response_model=UserProfileResponse,
    dependencies=[Depends(verify_api_key)],
)
def get_user_profile(
    user_id: str = Depends(get_user_id), session: Session = Depends(get_session)
):
    """Get complete user profile (personal info + work history)"""
    user, personal = get_or_create_user_profile(session, user_id)

    return {
        "user_id": user.user_id,
        "profile_data": json.loads(user.profile_data),
        "personal_info": {
            "name": personal.name,
            "email": personal.email,
            "phone": personal.phone,
            "country_code": personal.country_code,
            "location": personal.location,
            "social_networks": json.loads(personal.social_networks),
        },
        "created_at": user.created_at,
        "updated_at": user.updated_at,
    }


@app.put("/users/personal-info", dependencies=[Depends(verify_api_key)])
def update_personal_info(
    data: PersonalInfoUpdate,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Update personal contact information"""
    _, personal = get_or_create_user_profile(session, user_id)

    personal.name = data.name
    personal.email = data.email
    personal.phone = data.phone
    personal.country_code = data.country_code
    personal.location = data.location

    if data.social_networks:
        personal.social_networks = json.dumps(data.social_networks)

    personal.updated_at = datetime.now()
    session.add(personal)
    session.commit()

    return {"status": "updated", "user_id": user_id}


@app.put("/users/profile-data", dependencies=[Depends(verify_api_key)])
def update_profile_data(
    data: ProfileDataUpdate,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Update user's work history, education, skills"""
    user, _ = get_or_create_user_profile(session, user_id)

    current_data = json.loads(user.profile_data)

    if data.education is not None:
        current_data["education"] = data.education
    if data.experience is not None:
        current_data["experience"] = data.experience
    if data.skills is not None:
        current_data["skills"] = data.skills

    user.profile_data = json.dumps(current_data)
    user.updated_at = datetime.now()

    session.add(user)
    session.commit()

    return {"status": "updated", "user_id": user_id}


# ============================================================================
# API Endpoints - Job & Resume Management
# ============================================================================
@app.get("/users/jobs", dependencies=[Depends(verify_api_key)])
def get_user_jobs(
    user_id: str = Depends(get_user_id), session: Session = Depends(get_session)
):
    """Get all job descriptions submitted by user"""
    jobs = session.exec(
        select(JobDescription)
        .where(JobDescription.user_id == user_id)
        .order_by(JobDescription.created_at.desc())
    ).all()

    return {
        "user_id": user_id,
        "count": len(jobs),
        "jobs": [
            {
                "id": j.id,
                "title": j.title,
                "company": j.company,
                "created_at": j.created_at,
            }
            for j in jobs
        ],
    }


@app.get("/users/tasks", dependencies=[Depends(verify_api_key)])
def get_user_tasks(
    user_id: str = Depends(get_user_id), session: Session = Depends(get_session)
):
    """Get all tasks for a specific user"""
    tasks = session.exec(
        select(TaskLog)
        .where(TaskLog.user_id == user_id)
        .order_by(TaskLog.created_at.desc())
    ).all()

    return {
        "user_id": user_id,
        "count": len(tasks),
        "tasks": [
            {
                "task_id": t.task_id,
                "status": t.status,
                "total_tokens": t.total_tokens,
                "created_at": t.created_at,
                "pdf_url": f"/download/{t.task_id}/{Path(t.pdf_path).name}"
                if t.pdf_path
                else None,
            }
            for t in tasks
        ],
    }


@app.get(
    "/resume-content/{task_id}",
    response_model=ResumeContentResponse,
    dependencies=[Depends(verify_api_key)],
)
def get_resume_content(
    task_id: str,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Fetch the AI-generated resume JSON"""
    resume = session.exec(
        select(ResumeContent)
        .where(ResumeContent.task_id == task_id)
        .where(ResumeContent.user_id == user_id)
    ).first()

    if not resume:
        raise HTTPException(status_code=404, detail="Resume content not found")

    return {
        "task_id": resume.task_id,
        "job_id": resume.job_id,
        "content": json.loads(resume.content),
        "created_at": resume.created_at,
    }


@app.get(
    "/analysis/{task_id}",
    response_model=AnalysisContentResponse,
    dependencies=[Depends(verify_api_key)],
)
def get_analysis(
    task_id: str,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Get job analysis for a specific task"""
    task = session.get(TaskLog, task_id)
    if not task or task.user_id != user_id:
        raise HTTPException(status_code=404, detail="Task not found")

    analysis = session.exec(
        select(JobAnalysis)
        .where(JobAnalysis.job_id == task.job_id)
        .where(JobAnalysis.user_id == user_id)
        .order_by(JobAnalysis.id.desc())
    ).first()

    if not analysis:
        raise HTTPException(status_code=404, detail="Analysis not found")

    return {
        "task_id": task_id,
        "job_id": task.job_id,
        "analysis_text": analysis.analysis_text,
    }


# --- Job Submission (One-Shot) ---
@app.post(
    "/submit-job-complete",
    response_model=TaskResponse,
    dependencies=[Depends(verify_api_key)],
)
def submit_job_complete(
    request: JobRequest,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Submit job and automatically run analysis + resume generation"""
    task_id = str(uuid.uuid4())
    content_hash = hashlib.sha256(
        request.description.strip().encode("utf-8")
    ).hexdigest()

    task = TaskLog(
        task_id=task_id,
        user_id=user_id,
        status="pending",
        logs=[f"[{datetime.now()}] Task created (One-Shot)"],
    )

    # Check for cached analysis for THIS USER
    existing_jd = session.exec(
        select(JobDescription)
        .where(JobDescription.content_hash == content_hash)
        .where(JobDescription.user_id == user_id)
    ).first()

    if existing_jd:
        task.job_id = existing_jd.id
        existing_analysis = session.exec(
            select(JobAnalysis)
            .where(JobAnalysis.job_id == existing_jd.id)
            .where(JobAnalysis.user_id == user_id)
        ).first()

        if existing_analysis:
            task.status = "analysis_complete"
            task.logs.append(f"[{datetime.now()}] Cache hit. Skipping analysis.")
            session.add(task)
            session.commit()
            process_resume_task(task_id)
            return {
                "task_id": task_id,
                "status": "resume_pending",
                "message": "Analysis cached. Resume generation started.",
            }

        session.add(task)
        session.commit()
        process_analysis_task(
            task_id,
            user_id,
            request.title,
            request.company,
            request.description,
            existing_jd.id,
            auto_resume=True,
        )
        return {
            "task_id": task_id,
            "status": "analysis_pending",
            "message": "JD found. Starting Analysis -> Resume.",
        }

    new_jd = JobDescription(
        user_id=user_id,
        title=request.title,
        company=request.company,
        description=request.description,
        content_hash=content_hash,
    )
    session.add(new_jd)
    session.commit()
    session.refresh(new_jd)

    task.job_id = new_jd.id
    session.add(task)
    session.commit()

    process_analysis_task(
        task_id,
        user_id,
        request.title,
        request.company,
        request.description,
        new_jd.id,
        auto_resume=True,
    )

    return {
        "task_id": task_id,
        "status": "analysis_pending",
        "message": "Job submitted. Starting Analysis -> Resume.",
    }


# --- Job Submission (Two-Step) ---
@app.post(
    "/submit-job", response_model=TaskResponse, dependencies=[Depends(verify_api_key)]
)
def submit_job(
    request: JobRequest,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Submit job for analysis only (manual resume generation trigger)"""
    task_id = str(uuid.uuid4())
    content_hash = hashlib.sha256(
        request.description.strip().encode("utf-8")
    ).hexdigest()

    task = TaskLog(
        task_id=task_id,
        user_id=user_id,
        status="pending",
        logs=[f"[{datetime.now()}] Task created"],
    )

    existing_jd = session.exec(
        select(JobDescription)
        .where(JobDescription.content_hash == content_hash)
        .where(JobDescription.user_id == user_id)
    ).first()

    if existing_jd:
        task.job_id = existing_jd.id
        existing_analysis = session.exec(
            select(JobAnalysis)
            .where(JobAnalysis.job_id == existing_jd.id)
            .where(JobAnalysis.user_id == user_id)
        ).first()

        if existing_analysis:
            task.status = "analysis_complete"
            task.logs.append(f"[{datetime.now()}] Used cached analysis")
            session.add(task)
            session.commit()
            return {
                "task_id": task_id,
                "status": "analysis_complete",
                "message": "Analysis loaded from cache",
            }

        session.add(task)
        session.commit()
        process_analysis_task(
            task_id,
            user_id,
            request.title,
            request.company,
            request.description,
            existing_jd.id,
            auto_resume=False,
        )
        return {
            "task_id": task_id,
            "status": "analysis_pending",
            "message": "JD found, starting analysis",
        }

    new_jd = JobDescription(
        user_id=user_id,
        title=request.title,
        company=request.company,
        description=request.description,
        content_hash=content_hash,
    )
    session.add(new_jd)
    session.commit()
    session.refresh(new_jd)

    task.job_id = new_jd.id
    session.add(task)
    session.commit()

    process_analysis_task(
        task_id,
        user_id,
        request.title,
        request.company,
        request.description,
        new_jd.id,
        auto_resume=False,
    )

    return {
        "task_id": task_id,
        "status": "analysis_pending",
        "message": "Job submitted, analysis started",
    }


@app.post(
    "/generate-resume/{task_id}",
    response_model=TaskResponse,
    dependencies=[Depends(verify_api_key)],
)
def trigger_resume(
    task_id: str,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Manually trigger resume generation after analysis"""
    task = session.get(TaskLog, task_id)
    if not task or task.user_id != user_id:
        raise HTTPException(status_code=404, detail="Task not found")

    if "analysis_complete" not in task.status and "resume" not in task.status:
        raise HTTPException(status_code=400, detail="Analysis not yet complete")

    task.status = "resume_pending"
    session.add(task)
    session.commit()

    process_resume_task(task_id)

    return {
        "task_id": task_id,
        "status": "resume_pending",
        "message": "Resume generation started",
    }


@app.get(
    "/status/{task_id}",
    response_model=StatusResponse,
    dependencies=[Depends(verify_api_key)],
)
def get_task_status(
    task_id: str,
    user_id: str = Depends(get_user_id),
    session: Session = Depends(get_session),
):
    """Get status of a specific task"""
    task = session.get(TaskLog, task_id)
    if not task or task.user_id != user_id:
        raise HTTPException(status_code=404, detail="Task not found")

    pdf_url = None
    if task.status == "resume_complete" and task.pdf_path:
        filename = Path(task.pdf_path).name
        pdf_url = f"/download/{task_id}/{filename}"  # Updated URL format

    return {
        "task_id": task.task_id,
        "status": task.status,
        "logs": task.logs,
        "total_tokens": task.total_tokens,
        "pdf_url": pdf_url,
        "output_folder": task.output_folder,
    }


@app.get("/stats", response_model=StatsResponse, dependencies=[Depends(verify_api_key)])
def get_stats(
    user_id: str = Depends(get_user_id), session: Session = Depends(get_session)
):
    """Get user-specific statistics"""
    tasks = session.exec(
        select(TaskLog)
        .where(TaskLog.user_id == user_id)
        .order_by(TaskLog.created_at.desc())
        .limit(10)
    ).all()

    all_time_tokens = sum(
        [
            t.total_tokens
            for t in session.exec(
                select(TaskLog).where(TaskLog.user_id == user_id)
            ).all()
        ]
    )

    recent_list = [
        {
            "id": t.task_id,
            "status": t.status,
            "tokens": t.total_tokens,
            "time": t.created_at,
        }
        for t in tasks
    ]

    return {
        "total_tasks": len(recent_list),
        "total_tokens_used": all_time_tokens,
        "recent_tasks": recent_list,
    }


@app.get("/download/{task_id}/{filename}")
def download_file(
    task_id: str,
    filename: str,
    x_api_key: str = Header(...),
    x_user_id: str = Header(...),
):
    """Download PDF file from task-specific folder"""
    if x_api_key != API_TOKEN:
        raise HTTPException(status_code=401, detail="Unauthorized")

    # Verify task belongs to user
    with Session(engine) as session:
        task = session.get(TaskLog, task_id)
        if not task or task.user_id != x_user_id:
            raise HTTPException(status_code=404, detail="Task not found")

    file_path = Path("output") / task_id / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="File not found")

    return FileResponse(path=file_path, filename=filename, media_type="application/pdf")
